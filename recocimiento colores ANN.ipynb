{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "959ad801",
   "metadata": {},
   "source": [
    "### importamos las librerias a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab0dac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input, Dropout\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012439b",
   "metadata": {},
   "source": [
    "### Preparacion de espacio de trabajo\n",
    "\n",
    "especificamos la ruta de nuestro dataset, un arreglo para guardar las categorias que vayamos encontrando y la dimension a trabajar con nuestras imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6685ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '/home/lenin/Documents/datasets/colores'\n",
    "CATEGORIES = []\n",
    "IMG_SIZE=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e7850",
   "metadata": {},
   "source": [
    "recorremos el direcotorio excluyendo las imagenes de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6fba52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorias encontradas: ['morado', 'azul', 'rojo', 'amarillo', 'gris', 'rosado', 'negro', 'naranja', 'celeste', 'verde', 'blanco', 'cafe']\n",
      " total: 12\n"
     ]
    }
   ],
   "source": [
    "for cate in os.listdir(DATADIR):\n",
    "    if cate == 'testimg': continue\n",
    "    CATEGORIES.append(cate)\n",
    "print(f'categorias encontradas: {CATEGORIES}\\n total: {len(CATEGORIES)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639757ce",
   "metadata": {},
   "source": [
    "### Recoleccion de datos\n",
    "recorremos el directorio tomando cada imagen segun su respectiva categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614c1cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenin/.local/lib/python3.10/site-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "training_data=[] #var para los datos recolectados\n",
    "labels=0\n",
    "for category in CATEGORIES:\n",
    "    path=os.path.join(DATADIR, category)\n",
    "    for fname in os.listdir(path):\n",
    "        img = load_img((path+'/'+fname), target_size=(IMG_SIZE,IMG_SIZE))\n",
    "        x = img_to_array(img)\n",
    "        x=x/255\n",
    "        training_data.append([x,labels])\n",
    "    labels+=1\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df437530",
   "metadata": {},
   "source": [
    "verificamos el total de datos que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "376f016e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50400\n"
     ]
    }
   ],
   "source": [
    "lenofimage = len(training_data)\n",
    "print(lenofimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafca375",
   "metadata": {},
   "source": [
    "### Tratamiento de los datos\n",
    "separamos  nuestra data en img-labels y los tratamos con numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bf3f7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "for img, label in training_data:\n",
    "    X.append(img)\n",
    "    y.append(label)\n",
    "print('done')\n",
    "del training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a4673",
   "metadata": {},
   "source": [
    "verificamos la forma de nuestra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4777655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels (50400,)\n",
      "img (50400, 5, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "print('labels',y.shape)\n",
    "print('img',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c237d2a",
   "metadata": {},
   "source": [
    "dividimos la data para train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7f07e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 37800, test: 12600\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "print(f'train: {len(X_train)}, test: {len(X_test)}')\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de46ea7",
   "metadata": {},
   "source": [
    "### Creacion del modelo\n",
    "creamos la arquitectura del modelo, lo compilamos y finalmente ajustamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8fcbd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Flatten(input_shape=(X_train[0].shape)))\n",
    "# model.add(Dense(len(CATEGORIES), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13233a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (2,2), activation='relu', padding='SAME', input_shape=X_train[0].shape),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(len(CATEGORIES), activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab8aff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='SAME', input_shape=X_train[0].shape))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='SAME', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(len(CATEGORIES), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb69ae71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "945/945 [==============================] - 4s 3ms/step - loss: 0.6832 - accuracy: 0.7771\n",
      "Epoch 2/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.3725 - accuracy: 0.8652\n",
      "Epoch 3/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.3485 - accuracy: 0.8713\n",
      "Epoch 4/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.3361 - accuracy: 0.8741\n",
      "Epoch 5/60\n",
      "945/945 [==============================] - 4s 4ms/step - loss: 0.3253 - accuracy: 0.8775\n",
      "Epoch 6/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.3127 - accuracy: 0.8825\n",
      "Epoch 7/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.3074 - accuracy: 0.8834\n",
      "Epoch 8/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.3008 - accuracy: 0.8846\n",
      "Epoch 9/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2928 - accuracy: 0.8889\n",
      "Epoch 10/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2885 - accuracy: 0.8906\n",
      "Epoch 11/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2861 - accuracy: 0.8913\n",
      "Epoch 12/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2816 - accuracy: 0.8919\n",
      "Epoch 13/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2773 - accuracy: 0.8934\n",
      "Epoch 14/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2748 - accuracy: 0.8948\n",
      "Epoch 15/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2741 - accuracy: 0.8953\n",
      "Epoch 16/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2672 - accuracy: 0.8985\n",
      "Epoch 17/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2649 - accuracy: 0.8987\n",
      "Epoch 18/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2606 - accuracy: 0.9014\n",
      "Epoch 19/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2580 - accuracy: 0.9020\n",
      "Epoch 20/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2582 - accuracy: 0.9027\n",
      "Epoch 21/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2540 - accuracy: 0.9037\n",
      "Epoch 22/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2469 - accuracy: 0.9057\n",
      "Epoch 23/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2472 - accuracy: 0.9051\n",
      "Epoch 24/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2458 - accuracy: 0.9067\n",
      "Epoch 25/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2429 - accuracy: 0.9087\n",
      "Epoch 26/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2407 - accuracy: 0.9082\n",
      "Epoch 27/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2420 - accuracy: 0.9077\n",
      "Epoch 28/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2382 - accuracy: 0.9092\n",
      "Epoch 29/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2361 - accuracy: 0.9091\n",
      "Epoch 30/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2339 - accuracy: 0.9120\n",
      "Epoch 31/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2326 - accuracy: 0.9107\n",
      "Epoch 32/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2280 - accuracy: 0.9133\n",
      "Epoch 33/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2282 - accuracy: 0.9134\n",
      "Epoch 34/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2249 - accuracy: 0.9142\n",
      "Epoch 35/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2256 - accuracy: 0.9133\n",
      "Epoch 36/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2238 - accuracy: 0.9162\n",
      "Epoch 37/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2202 - accuracy: 0.9160\n",
      "Epoch 38/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2222 - accuracy: 0.9173\n",
      "Epoch 39/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2192 - accuracy: 0.9162\n",
      "Epoch 40/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2182 - accuracy: 0.9168\n",
      "Epoch 41/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2151 - accuracy: 0.9190\n",
      "Epoch 42/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2155 - accuracy: 0.9190\n",
      "Epoch 43/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2113 - accuracy: 0.9206\n",
      "Epoch 44/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2142 - accuracy: 0.9194\n",
      "Epoch 45/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2104 - accuracy: 0.9212\n",
      "Epoch 46/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2103 - accuracy: 0.9217\n",
      "Epoch 47/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2092 - accuracy: 0.9210\n",
      "Epoch 48/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2069 - accuracy: 0.9220\n",
      "Epoch 49/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2057 - accuracy: 0.9228\n",
      "Epoch 50/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2020 - accuracy: 0.9255\n",
      "Epoch 51/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2034 - accuracy: 0.9243\n",
      "Epoch 52/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.2012 - accuracy: 0.9253\n",
      "Epoch 53/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.1990 - accuracy: 0.9253\n",
      "Epoch 54/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.1980 - accuracy: 0.9280\n",
      "Epoch 55/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.1987 - accuracy: 0.9256\n",
      "Epoch 56/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.1973 - accuracy: 0.9266\n",
      "Epoch 57/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.1955 - accuracy: 0.9271\n",
      "Epoch 58/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.1953 - accuracy: 0.9263\n",
      "Epoch 59/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.1912 - accuracy: 0.9290\n",
      "Epoch 60/60\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.1915 - accuracy: 0.9283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb43f491480>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=60, batch_size=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99addcd6",
   "metadata": {},
   "source": [
    "verificamos la precision en testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05634151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.20686516165733337\n",
      "test accuracy 0.9254761934280396\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('test loss',test_loss)\n",
    "print('test accuracy',test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906391c4",
   "metadata": {},
   "source": [
    "### Probamos el modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1430fdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediccion = cafe\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ruta a nuestras imagenes de test en el directorio, no de la data preparada\n",
    "path = DATADIR + '/testimg' + '/17.jpeg' \n",
    "\n",
    "#tratamos la img con el mismo tamanio y la normalizamos\n",
    "img = load_img(path, target_size=(IMG_SIZE,IMG_SIZE))\n",
    "x = img_to_array(img)\n",
    "x=x/255\n",
    "\n",
    "#agrego un eje para que el modelo lo reciba\n",
    "x = x[np.newaxis, ...]\n",
    "\n",
    "#imprimo la img y la prediccion\n",
    "plt.imshow(img)\n",
    "resp = model.predict(x, verbose=0)\n",
    "print(f'prediccion = {CATEGORIES[np.argmax(resp[0])]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b62849",
   "metadata": {},
   "source": [
    "### Exportacion\n",
    "con el modelo ya funcionando correctamente, lo exportamos para poder utilizarlo en otros proyectos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56d6e997",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mod_color_v1.h5')\n",
    "model.save_weights(\"mod_color_v1_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5281d610",
   "metadata": {},
   "source": [
    "para cargarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d3444ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cargar la estructura del modelo\n",
    "# modelo_cargado = tf.keras.models.load_model(\"mod_color_v1.h5\")\n",
    "\n",
    "# # Cargar los pesos del modelo\n",
    "# modelo_cargado.load_weights(\"mod_color_v1_weights.h5\")\n",
    "convd \n",
    "drop out \n",
    "max poling \n",
    "padding \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
